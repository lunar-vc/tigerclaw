# Agent Memory Architecture Researchers

**Date:** 2026-02-11
**Analyst:** Claude (Tigerclaw)
**Type:** Founder Research

## Executive Summary

Research profiles on three researchers working on agent memory architectures: Sizhe Yuen (Intrinsic Memory Agents), Nikhil Verma (Focus context compression), and Qizheng Zhang (ACE context engineering). Yuen is a PhD student/research assistant at the Alan Turing Institute with an academic profile and no commercialization signals. Verma is an industry AI researcher at LG Electronics Toronto AI Lab, publishing prolifically on agent systems but showing no startup signals. Zhang is a 4th-year Stanford PhD student whose adjacent project LMCache has already been commercialized as Tensormesh ($4.5M seed), though Zhang himself does not appear to be a co-founder of that company.

---

## 1. Sizhe Yuen

### Profile

| Field | Detail |
|-------|--------|
| **Current role** | Researcher, Data-Centric Engineering, The Alan Turing Institute |
| **PhD status** | PhD student, University of Southampton (ongoing) |
| **PhD topic** | Epigenetic mechanisms in evolutionary algorithms for dynamic multi-objective search problems |
| **Supervisor** | Adam J. Sobey (University of Southampton + Alan Turing Institute) |
| **Prior education** | BSc Computer Science, University of St Andrews (2019) |
| **Location** | London, UK |

### Key Paper

**"Intrinsic Memory Agents: Heterogeneous Multi-Agent LLM Systems through Structured Contextual Memory"**
- arXiv: [2508.08997](https://arxiv.org/abs/2508.08997) (August 2025)
- Co-authors: Francisco Gomez Medina, Ting Su (Alan Turing Institute), Yali Du (King's College London), Adam J. Sobey (Southampton/Turing)
- Contribution: Framework for structured agent-specific memories that evolve intrinsically with agent outputs, maintaining role-aligned memory templates

### Online Presence

| Platform | Link |
|----------|------|
| **LinkedIn** | [linkedin.com/in/sizhe/](https://www.linkedin.com/in/sizhe/) |
| **GitHub** | [github.com/12yuens2](https://github.com/12yuens2) (43 repos, 27 followers) |
| **Turing profile** | [turing.ac.uk/people/sizhe-yuen](https://www.turing.ac.uk/people/sizhe-yuen) |
| **Southampton profile** | [southampton.ac.uk/people/5xvv99/mr-sizhe-yuen](https://www.southampton.ac.uk/people/5xvv99/mr-sizhe-yuen) |
| **Twitter/X** | Not found |

### GitHub Analysis

GitHub repos are primarily academic coursework and hobby projects: Haskell Othello game, C filesystem, Starcraft 2 optimizer, Turing machine implementation, LaTeX report templates. No repos related to agent memory, LLMs, or any commercial/startup activity. Primary languages: Haskell, C, Java, LaTeX. Arctic Code Vault Contributor.

### Other Publications

- "Epigenetic opportunities for evolutionary computation" (Royal Society Open Science, 2023) -- with Thomas Ezard and Adam Sobey
- Earlier work on Dota 2 analysis and evolutionary computation

### Commercialization Signals

**None detected.** Profile is purely academic. No startup activity, no commercial repos, no venture-related LinkedIn activity. The IMA paper comes from his Turing Institute research work, not a venture. PhD appears to still be in progress (Southampton page lists him as "Mr Sizhe Yuen").

### Assessment

- **Signal strength:** Weak (for venture purposes)
- **Thesis fit:** Adjacent (agent memory is relevant, but researcher is academic-track)
- **Action:** WATCH -- Monitor for PhD completion and any post-graduation career moves. The IMA framework is interesting technically but the researcher shows no builder/founder pattern.

---

## 2. Nikhil Verma

### Profile

| Field | Detail |
|-------|--------|
| **Current role** | AI Research Scientist, LG Electronics Toronto AI Lab (since Jan 2023) |
| **Education** | MSc Applied Computing, University of Toronto (2021-2022) |
| **Prior education** | B.Eng, Thapar University; coursework/certificate from IIT Delhi |
| **Prior role** | Senior Software Engineer, InfoEdge India Ltd (Brijj.com); Software Intern, Mentor Graphics |
| **Location** | Toronto, Canada |

### Key Paper

**"Active Context Compression: Autonomous Memory Management in LLM Agents"**
- arXiv: [2601.07190](https://arxiv.org/abs/2601.07190) (January 12, 2026)
- **Sole author** -- no co-authors, no listed institutional affiliation on the paper
- Contribution: "Focus" architecture inspired by Physarum polycephalum (slime mold) for autonomous context management in LLM agents
- Result: 22.7% token reduction while maintaining identical accuracy on SWE-bench Lite

### Other Publications (LG Toronto AI Lab)

- **"GEMMAS: Graph-based Evaluation Metrics for Multi Agent Systems"** (EMNLP 2025 Industry Track, [arXiv 2507.13190](https://arxiv.org/abs/2507.13190)) -- with Jisoo Lee, Raeyoung Chang, Dongwook Kwon, Harmanpreet Singh
- **"GPT-Detox: An In-Context Learning-Based Paraphraser for Text Detoxification"** ([arXiv 2404.03052](https://arxiv.org/abs/2404.03052)) -- with Ali Pesaranghader, Manasa Bharadwaj (LG Toronto AI Lab)
- **"The Hidden Space of Safety: Understanding Preference-Tuned LLMs in Multilingual context"** -- LG/UofT collaboration
- **"Diffusion idea exploration for art generation"** (arXiv 2307.04978, 2023) -- with Scott Sanner (UofT)
- Personal LLM agent work published at EMNLP 2024 Industry Track

### Online Presence

| Platform | Link |
|----------|------|
| **LinkedIn** | [linkedin.com/in/lihkinVerma/](https://www.linkedin.com/in/lihkinVerma/) |
| **GitHub** | [github.com/lihkinVerma](https://github.com/lihkinVerma) (32 repos, 9 followers) |
| **Portfolio** | [lihkinverma.github.io/portfolio/](https://lihkinverma.github.io/portfolio/) |
| **Medium** | [lih-verma.medium.com](https://lih-verma.medium.com/) |
| **Twitter/X** | [@lihkinVer](https://twitter.com/lihkinVer) |
| **OpenReview** | [openreview.net/profile?id=~Nikhil_Verma2](https://openreview.net/profile?id=~Nikhil_Verma2) |
| **ResearchGate** | [researchgate.net/scientific-contributions/Nikhil-Verma-2268377230](https://www.researchgate.net/scientific-contributions/Nikhil-Verma-2268377230) |
| **Email** | lih.verma@gmail.com / nikhil.verma@lge.com |

### GitHub Analysis

32 repos, primarily Python. Pinned projects: DiffusionModel (4 stars), Image-Reconstruction-by-Vision-Transformer (14 stars), Automatic-Handwriting-Processing (7 stars), alphaNumericCaptchaCrack, Mathematics-behind-machine-learning, Optimization-Algorithms. No repos related to the Focus architecture or agent memory systems. No open-source release of Focus detected.

### Commercialization Signals

**None detected.** Verma is firmly in industry research at LG. His LinkedIn describes himself as "an assimilator in the field of Artificial General Intelligence(AGI)." The Focus paper was published as a sole-author work, which is notable -- it suggests personal research initiative beyond his LG role. He attended ACL 2025 and is actively publishing. However:
- No startup signals, no venture activity
- Still employed at LG (ZoomInfo confirms n***@lge.com email active)
- No open-source release of the Focus framework
- The Focus paper was published without institutional affiliation, which is unusual -- could indicate it's a side project

### Assessment

- **Signal strength:** Medium (sole-author paper on a novel agent architecture is noteworthy, but no startup signals)
- **Thesis fit:** Adjacent (agent memory/context management is relevant, researcher is industry-track)
- **Action:** WATCH -- The sole-author Focus paper shows independent research ambition. Monitor for departure from LG, open-sourcing of Focus, or any venture activity. His AGI-focused self-description and growing publication record suggest potential future founder material, but timing is unclear.

---

## 3. Qizheng Zhang

### Profile

| Field | Detail |
|-------|--------|
| **Current role** | 4th-year CS PhD student, Stanford University (admitted Autumn 2022) |
| **Advisor** | Kunle Olukotun (Cadence Design Systems Professor of CS, Stanford) |
| **Collaborators** | James Zou (Stanford), Junchen Jiang (UChicago), Muhammad Shahbaz |
| **Lab** | Stanford Pervasive Parallelism Lab (PPL); LMCache project |
| **Prior education** | UChicago (undergrad) |
| **Prior experience** | Microsoft Research (internship, per LinkedIn) |
| **Location** | Stanford, CA |
| **Citations** | 1,153 (Google Scholar) |

### Key Paper

**"Agentic Context Engineering: Evolving Contexts for Self-Improving Language Models"**
- arXiv: [2510.04618](https://arxiv.org/abs/2510.04618) (October 2025)
- Co-authors: Changran Hu (SambaNova), Shubhangi Upasani, Boyuan Ma, Fenglu Hong, Vamsidhar Kamanuru, Jay Rainton, Chen Wu, Mengmeng Ji (all SambaNova), Hanchen Li (UC Berkeley), Urmish Thakker (SambaNova), James Zou (Stanford), Kunle Olukotun (Stanford)
- Joint work between Stanford, SambaNova Systems, and UC Berkeley
- Contribution: ACE framework for self-improving LLMs through evolving, structured contexts rather than weight updates
- Results: +10.6% on agent tasks, +8.6% on finance; -86.9% latency, -83.6% cost
- Open source: [github.com/ace-agent/ace](https://github.com/ace-agent/ace) (598 stars)

### Other Notable Publications

- **CacheGen** (SIGCOMM 2024): KV Cache Compression and Streaming for Fast LLM Serving
- **CacheBlend** (EuroSys 2025): Fast LLM Serving for RAG with Cached Knowledge Fusion
- **Caravan** (OSDI 2024): Agent-Based Generative Data Labeling
- **Minions**: Big & Small LLMs working together (1.3k stars on GitHub)
- Papers at ICLR 2026, NeurIPS 2025, ICML 2025

### Online Presence

| Platform | Link |
|----------|------|
| **Personal site** | [alex-q-z.github.io](https://alex-q-z.github.io/) |
| **LinkedIn** | [linkedin.com/in/qizheng-alex-zhang/](https://www.linkedin.com/in/qizheng-alex-zhang/) |
| **GitHub** | [github.com/Alex-q-z](https://github.com/Alex-q-z) (23 repos, 90 followers) |
| **Twitter/X** | [@qizhengz_alex](https://x.com/qizhengz_alex) (624 following) |
| **Google Scholar** | [scholar.google.com/citations?user=xnt6d5oAAAAJ](https://scholar.google.com/citations?user=xnt6d5oAAAAJ) |
| **Stanford profile** | [profiles.stanford.edu/qizheng-zhang](https://profiles.stanford.edu/qizheng-zhang) |
| **Email** | qizhengz@stanford.edu |

### GitHub Analysis

23 repos, heavily focused on LLM systems. Pinned repos: ACE (598 stars), ace-appworld (18 stars), LMCache (6.9k stars), dds (93 stars), minions (1.3k stars), caravan-ai (5 stars). Active contributor to the ace-agent GitHub org. All repos are research-oriented open source -- no commercial product repos.

### Commercialization / Tensormesh Connection

**Critical finding:** Zhang is a co-author on CacheGen and CacheBlend, both core papers behind LMCache. The LMCache project has been commercialized as **Tensormesh**, which emerged from stealth in October 2025 with **$4.5M seed funding led by Laude Ventures** (Source: [TechCrunch](https://techcrunch.com/2025/10/23/tensormesh-raises-4-5m-to-squeeze-more-inference-out-of-ai-server-loads/)).

However, **Zhang does not appear to be a Tensormesh co-founder.** The Tensormesh founding team is:
- **Junchen Jiang** (CEO) -- Professor at UChicago, co-creator of LMCache
- **Yihua Cheng** (CTO) -- PhD from UChicago, launched and maintained LMCache

Zhang is listed as a contributor/co-author on LMCache papers but is not part of the Tensormesh leadership. He remains a Stanford PhD student focused on his own research agenda (ACE, agents, systems).

### Assessment

- **Signal strength:** Medium (prolific researcher with high-impact work, but actively in PhD with no direct startup signals)
- **Thesis fit:** Direct (agent memory/context engineering is core to his research)
- **Action:** WATCH -- Zhang is the most commercially proximate of the three researchers. His work on ACE is directly relevant to agent infrastructure, he has industry connections (SambaNova collaboration, Microsoft internship), and he's in the Stanford ecosystem where commercialization is culturally encouraged. Expected PhD completion ~2026-2027. His LMCache co-authorship shows he builds things that get commercialized, even if he isn't the one commercializing them (yet). Monitor for: PhD defense timeline, any new GitHub orgs, Stanford entrepreneurship activity, departure signals.

---

## Comparative Summary

| Researcher | Affiliation | PhD Status | Commercialization Signals | Signal Strength | Action |
|-----------|-------------|------------|--------------------------|----------------|--------|
| Sizhe Yuen | Alan Turing Institute / U. Southampton | In progress | None | Weak | WATCH |
| Nikhil Verma | LG Electronics Toronto AI Lab | N/A (MSc completed) | None (sole-author paper is notable) | Medium | WATCH |
| Qizheng Zhang | Stanford University | 4th year (expected 2026-2027) | Adjacent (LMCache -> Tensormesh, but not a founder) | Medium | WATCH |

## Sources

- [arXiv 2508.08997 - Intrinsic Memory Agents](https://arxiv.org/abs/2508.08997)
- [arXiv 2601.07190 - Active Context Compression (Focus)](https://arxiv.org/abs/2601.07190)
- [arXiv 2510.04618 - Agentic Context Engineering (ACE)](https://arxiv.org/abs/2510.04618)
- [Sizhe Yuen - Alan Turing Institute](https://www.turing.ac.uk/people/sizhe-yuen)
- [Sizhe Yuen - LinkedIn](https://www.linkedin.com/in/sizhe/)
- [Sizhe Yuen - GitHub](https://github.com/12yuens2)
- [Sizhe Yuen - University of Southampton](https://www.southampton.ac.uk/people/5xvv99/mr-sizhe-yuen)
- [Nikhil Verma - LinkedIn](https://www.linkedin.com/in/lihkinVerma/)
- [Nikhil Verma - GitHub](https://github.com/lihkinVerma)
- [Nikhil Verma - Portfolio](https://lihkinverma.github.io/portfolio/)
- [Nikhil Verma - Medium](https://lih-verma.medium.com/)
- [Nikhil Verma - Twitter](https://twitter.com/lihkinVer)
- [Nikhil Verma - OpenReview](https://openreview.net/profile?id=~Nikhil_Verma2)
- [Nikhil Verma - ResearchGate](https://www.researchgate.net/scientific-contributions/Nikhil-Verma-2268377230)
- [Nikhil Verma - ZoomInfo](https://www.zoominfo.com/p/Nikhil-Verma/4074164643)
- [Nikhil Verma - Medium About](https://medium.com/@lih-verma/about)
- [Qizheng Zhang - Personal Site](https://alex-q-z.github.io/)
- [Qizheng Zhang - LinkedIn](https://www.linkedin.com/in/qizheng-alex-zhang/)
- [Qizheng Zhang - GitHub](https://github.com/Alex-q-z)
- [Qizheng Zhang - Twitter](https://x.com/qizhengz_alex)
- [Qizheng Zhang - Google Scholar](https://scholar.google.com/citations?user=xnt6d5oAAAAJ)
- [Qizheng Zhang - Stanford Profiles](https://profiles.stanford.edu/qizheng-zhang)
- [ACE GitHub Repo](https://github.com/ace-agent/ace)
- [LMCache](https://lmcache.ai/)
- [Tensormesh - TechCrunch](https://techcrunch.com/2025/10/23/tensormesh-raises-4-5m-to-squeeze-more-inference-out-of-ai-server-loads/)
- [Tensormesh - About](https://www.tensormesh.ai/about)
- [SambaNova ACE Blog Post](https://sambanova.ai/blog/ace-open-sourced-on-github)
- [GPT-Detox arXiv 2404.03052](https://arxiv.org/abs/2404.03052)
- [GEMMAS arXiv 2507.13190](https://arxiv.org/abs/2507.13190)
